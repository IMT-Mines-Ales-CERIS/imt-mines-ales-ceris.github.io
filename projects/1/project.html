<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <title>Portfolio - CERIS</title>

    <link href="../../css/style.css" rel="stylesheet">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
</head>

<body>
    <main>
        <section class="py-3 text-center container" id="header"></section>

        <div class="py-3 bg-body-tertiary">
            <div class="container-sm">                
                <div class="row">
                    <div class="col-md-12 mx-auto">
                        <nav style="--bs-breadcrumb-divider: '>';" aria-label="breadcrumb">
                            <ol class="breadcrumb">
                              <li class="breadcrumb-item"><a href="../../index.html">Accueil</a></li>
                              <li class="breadcrumb-item active" aria-current="page" id="short-title">Project name</li>
                            </ol>
                        </nav>

                        <h2 class="py-4" id="full-title">Lorem Ipsum: Aliquam sodales</h2>

                        <div>
                            <p class="text-justify">
                                L'interprétabilité des modèles prédictifs d'apprentissage automatique est cruciale pour de nombreux contextes applicatifs qui exigent que les décisions faites par les modèles soient comprises par les utilisateurs finaux (e.g. domaines critiques ou sensibles). Elle est aussi d’importance majeure afin d’implémenter des interactions Humain-IA de qualité, dans lesquelles l’Homme comprend la machine et s’enrichit de ses interactions avec elle. De nombreux travaux portent ainsi sur ces aspects d’interprétabilité, en lien étroit avec les problématiques de Confiance de l’IA, domaine considéré comme stratégique par la France dans son positionnement en IA.
                            </p>
                            <p class="text-justify">
                                Dans nos travaux sur ce sujet, l’interprétabilité des modèles d’apprentissage machine a été étudiée sous l'angle de l'explicabilité locale et des méthodes d'attribution. Celles-ci se concentrent sur l'explication d'une décision spécifique prise par un modèle pour une entrée donnée, en évaluant la contribution des caractéristiques de l'entrée aux résultats, par exemple la probabilité attribuée à une classe.  
                            </p>
                            <p class="text-justify">
                                De nombreuses méthodes d'attribution reposent sur une formulation du problème d'attribution basée sur la théorie des jeux et sur une approximation de la célèbre valeur de Shapley. Le calcul de l’indice de Shapley est cependant quadratique par rapport au nombre de caractéristiques de l’entrée, souvent comptées en milliers dans les applications récentes. 
                            </p>
                            <p class="text-justify">
                                Nos contributions portent sur la proposition de nouvelles approches efficaces. Dans l'article “Fair and Efficient Alternatives to Shapley-based Attribution Methods”, Charles Condevaux, Sébastien Harispe, Stéphane Mussard, publié à ECML PKDD 2022 avec nos collègues de l’équipe CHROME de l’Université de Nîmes, nous présentons la méthode d'attribution FESP (Fair-Efficient-Symmetric-Perturbation), une approche alternative partageant des propriétés axiomatiques pertinentes avec la valeur de Shapley et la valeur Equal Surplus (ES) couramment appliquée dans les jeux coopératifs. Nos résultats montrent que FESP et ES produisent de meilleures cartes d'attribution que les approches de l'état de l’art de 2022 dans le cadre de la classification d'images et de textes. 
                            </p>
                            <p class="text-justify">
                                Une implémentation de l’approche est partagée librement et gratuitement sur GitHub ; celle-ci permet l’utilisation des approches FESP et ES avec des modèles de Scikit-learn, ou encore implémentés en Pytorch ou via la librairie Transformers (Huggingface). 

                                En réponse à un manque identifié dans la littérature, nous proposons par ailleurs dans ce papier une approche d’évaluation innovante pour l’évaluation des méthodes d’interprétabilité locale à base d’attribution. L’ensemble des expérimentations effectuées sont de plus reproductibles.
                            </p>
                            <p class="text-justify">
                                Lien GitHub : <a href="https://github.com/ccdv-ai/fesp_es">Lien vers Github.</a>
                            </p>

                            <img src="images/1.png" class="img-fluid rounded py-3" alt="...">

                            <p class="text-justify">
                                Exemple de résultats d’attribution (top 10%) proposés par différentes approches dans le cas d’un classifieur binaire (classe chien/chat). Nous proposons la méthode Equal Surplus et FESP.  
                            </p>

                            <img src="images/2.png" class="img-fluid rounded py-3" alt="...">

                            <p class="text-justify">
                                Exemple de résultats d’attribution générés par les approches proposées et différentes approches de l’état de l’art. Les images composites ne contiennent qu’une zone contenant un chat ou un chien (la seule censée être détectée par l’approche). Contrairement à de nombreuses approches, ES et FESP arrivent à identifier les zones d’intérêt dans de nombreux cas.  
                            </p>
                            <div class="d-flex justify-content-center py-3" style="gap:20px">
                                <img src="images/6.gif" class="img-fluid w-100 h-auto rounded"  alt="...">
                                <img src="images/5.gif" class="img-fluid w-100 h-auto rounded" alt="...">                         
                            </div>
                        </div>
                        
                        <div id="carouselExampleIndicators" class="carousel carousel-dark slide">
                            <div class="carousel-indicators">
                                <button type="button" data-bs-target="#carouselExampleIndicators" data-bs-slide-to="0" class="active" aria-current="true" aria-label="Slide 1"></button>
                                <button type="button" data-bs-target="#carouselExampleIndicators" data-bs-slide-to="1" aria-label="Slide 2"></button>
                            </div>
                            <div class="carousel-inner">
                                <div class="carousel-item active">
                                    <img src="images/3.png" class="d-block w-100" alt="...">
                                </div>
                                <div class="carousel-item">
                                    <img src="images/4.png" class="d-block w-100" alt="...">
                                </div>                                  
                            </div>
                            <button class="carousel-control-prev" type="button" data-bs-target="#carouselExampleIndicators" data-bs-slide="prev">
                                <span class="carousel-control-prev-icon" aria-hidden="true"></span>
                                <span class="visually-hidden">Previous</span>
                            </button>
                            <button class="carousel-control-next" type="button" data-bs-target="#carouselExampleIndicators" data-bs-slide="next">
                                <span class="carousel-control-next-icon" aria-hidden="true"></span>
                                <span class="visually-hidden">Next</span>
                            </button>
                        </div>

                    </div>
                </div>
            </div>
        </div>
    </main>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz"
        crossorigin="anonymous"></script>

    <script>
        const myCarouselElement = document.querySelector('#carouselExampleIndicators')

        const carousel = new bootstrap.Carousel(myCarouselElement, {
            interval: 2000,
            touch: false
        });
    </script>

    <script src="../../js/header.js"></script>
    <script src="../../js/project.js"></script>
    <script>
        PROJECTS[0].FillPage();
    </script>

</body>

</html>